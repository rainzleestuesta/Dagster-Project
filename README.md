# NBA Stats Dagster Pipeline

This repository implements an end-to-end data pipeline for NBA analytics using Dagster. It scrapes, cleans, merges, validates, processes, and visualizes NBA player and team statistics, and schedules automated runs.


## ğŸš€ Project Structure
```
dagster_project/
â”œâ”€â”€ assets/
â”‚   â”œâ”€â”€ merge.py                   # Loads merged CSV into DataFrame
â”‚   â”œâ”€â”€ validate.py                # Data quality checks
â”‚   â”œâ”€â”€ process.py                 # Computes all-around z-scores
â”‚   â”œâ”€â”€ insights.py                # Visualization assets
â”œâ”€â”€ io_managers.py                 # CSV I/O manager (load & save)
â”œâ”€â”€ schedules.py                   # Dagster schedule & job definition
â”œâ”€â”€ repository.py                  # Defines assets, job, schedule
â”œâ”€â”€ workspace.yaml                 # Points to repository.py
â”œâ”€â”€ preprocess/                    # CSV & output folder
â”‚   â”œâ”€â”€ merged_players_team_stats.csv
â”‚   â”œâ”€â”€ processed_stats.csv        # Generated by pipeline
â”‚   â”œâ”€â”€ validated_stats.csv        # Validated data
|   â”œâ”€â”€ Scraped csv files          # Scraped data
|   â”œâ”€â”€ Python Scrapers            # Python codes used in scraping data
â”‚   â””â”€â”€ *.png                      # Insight charts
â””â”€â”€ README.md
```

---

## ğŸ› ï¸ Setup & Installation

1. **Clone the repo**
   ```bash
   git clone https://github.com/rainzleestuesta/Dagster-Project
   cd dagster_project
   ```
2. **Create & activate a virtual environment**
   ```bash
   python -m venv .venv
   source .venv/bin/activate      # macOS/Linux
   .venv\Scripts\activate       # Windows
   ```
3. **Install dependencies**
   ```bash
   pip install dagster dagster-webserver pandas matplotlib
   ```

---

## â–¶ï¸ Running Locally

1. **Start Dagster**
   ```bash
   dagster dev
   ```
2. **Open the UI**
   Navigate to http://localhost:3000
3. **Materialize Pipeline**
   - Under **Jobs**, select **stats_pipeline** and click **Launch Run**
   - Or under **Assets**, click **Materialize All**

Pipeline phases:
- **merged_stats**: load `merged_players_team_stats.csv`
- **validated_stats**: data quality checks
- **player_performance_metrics**: compute all-around z-scores
- **insights**: generate charts in `preprocess/*.png`

---

## ğŸ“… Schedule

The pipeline runs daily at 09:00 via the `daily_csv_schedule` (cron `0 9 * * *`).

---

## âœ… Data Quality Checks

- No nulls in key columns: `player`, `team_code`, `pts_per_game`, `win_percentage`
- `pts_per_game` between 0 and 40
- `win_percentage` between 0.0 and 1.0

---

## ğŸ“ˆ Insights & Outputs

- **Top 10 All-Around Players Based on z-scores**: `preprocess/top_all_around.png`
- **Top Scorers**: `preprocess/top_scorers.png`
- **Top Assist Leaders**: `preprocess/top_assists.png`
- **Team PPG Ranking**: `preprocess/team_ppg_ranking.png`
- **Best offensive teams**: `preprocess/best_offense.png`
- **Team Pace Ranking**: `preprocess/team_pace_ranking.png`
- **Net Rating vs Win% scatter plotr**: `preprocess/netrating_vs_win.png`

---

## ğŸ”„ Extending the Pipeline

- Add new assets in `assets/`
- Register them in `repository.py`
- Update `io_managers.py` for custom I/O
- Define new schedules in `schedules.py`

---

Happy analytics! ğŸ‰

